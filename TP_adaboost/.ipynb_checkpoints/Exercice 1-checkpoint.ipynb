{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%qtconsole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [e for e in range(1,21)]\n",
    "Y = [+1, +1, +1, +1, +1, -1, -1, -1, -1, -1, +1, +1, -1, -1, -1, -1, -1, +1, +1, +1]\n",
    "weights = [1/len(Y)]*20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weak_classif(x,theta,p):\n",
    "    if p == 1:\n",
    "        if x < theta:\n",
    "            return 1\n",
    "        else:\n",
    "            return -1\n",
    "    elif p == -1:\n",
    "        if x > theta:\n",
    "            return 1\n",
    "        else:\n",
    "            return -1\n",
    "    else:\n",
    "        raise Exception('p must be 1 or -1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_error(theta,p,X,Y,weights):\n",
    "    #return a list 'errors' with True if the prediction is wrong\n",
    "    #return the error\n",
    "    prediction = [weak_classif(x,theta,p) for x in X]\n",
    "    errors = [x!=y for (x,y) in zip (prediction,Y)]\n",
    "    error = 0\n",
    "    for i in range(len(errors)):\n",
    "        error += weights[i]*errors[i]\n",
    "    return {'errors': errors, 'error': error}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bestClassifier(X,Y,weights):\n",
    "    classifier_errors = []\n",
    "    for p in [1,-1]:\n",
    "        for x in X:\n",
    "            classifier_errors.append(classifier_error(x,p,X,Y,weights)['error'])\n",
    "    min_error = min(classifier_errors)\n",
    "    best_theta = (X*2)[classifier_errors.index(min_error)]\n",
    "    if classifier_errors.index(min_error) < 10:\n",
    "        best_p = 1\n",
    "    else:\n",
    "        best_p = -1\n",
    "    return {'theta': best_theta, 'p': best_p}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AdaBoost(X,Y,weights_0,N_it):\n",
    "    classifiers = []\n",
    "    weights = weights_0\n",
    "    for i in range(N_it):\n",
    "        best_classifier = bestClassifier(X,Y,weights)\n",
    "        theta = best_classifier['theta']\n",
    "        p = best_classifier['p']\n",
    "        classif_error = classifier_error(theta,p,X,Y,weights)\n",
    "        error, errors = classif_error['error'],classif_error['errors']\n",
    "        alpha = 0.5*np.log((1-error)/error)\n",
    "        classifiers.append([alpha,theta,p])\n",
    "        for i in range(len(X)):\n",
    "            if errors[i] == True:\n",
    "                weights[i] = weights[i]*np.exp(alpha)\n",
    "            else:\n",
    "                weights[i] = weights[i]*np.exp(-alpha)\n",
    "        Z = sum(weights)\n",
    "        weights = [e/Z for e in weights]\n",
    "    return classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5493061443340549, 6, 1], [0.34657359027997275, 10, -1], [-0.2027325540540819, 13, -1], [0.3465735902799723, 17, -1], [-0.25541281188299536, 13, -1]]\n"
     ]
    }
   ],
   "source": [
    "print(AdaBoost(X,Y,weights,5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
